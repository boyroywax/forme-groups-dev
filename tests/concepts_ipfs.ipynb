{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPFS Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPFS Service Node\n",
    "\n",
    "A node that is running the IPFS daemon and is connected to the IPFS network. It is able to provide content to other nodes and to retrieve content from other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# docker compose -f \"tests/ipfs/docker-compose.yml\" up -d --build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Server Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__IPFS_DEFAULT_URL__ = '/ip4/127.0.0.1/tcp/5001'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPFS-Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# pip install IPFS-Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipfs_api\n",
    "\n",
    "# Connect to the IPFS daemon\n",
    "def connect():\n",
    "    client = ipfs_api.ipfshttpclient\n",
    "    return client.connect(__IPFS_DEFAULT_URL__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client ID:  <ipfshttpclient2.client.base.ResponseBase: {'ID': '12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA', 'PublicKey': 'CAESILveCqhrvYi7xfZkCFoytPVThX++ztHAh85jBT3xQ0Et', 'Addresses': ['/ip4/108.61.182.184/tcp/4001/p2p/12D3KooWPuZGkjnjLso3sLgNm5qaQMgiX77ndQ14JHqR2TwWp3Be/p2p-circuit/p2p/12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA', '/ip4/108.61.182.184/udp/4001/quic-v1/p2p/12D3KooWPuZGkjnjLso3sLgNm5qaQMgiX77ndQ14JHqR2TwWp3Be/p2p-circuit/p2p/12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA', '/ip4/108.61.182.184/udp/4001/quic/p2p/12D3KooWPuZGkjnjLso3sLgNm5qaQMgiX77ndQ14JHqR2TwWp3Be/p2p-circuit/p2p/12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA', '/ip4/127.0.0.1/tcp/4001/p2p/12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA', '/ip4/127.0.0.1/udp/4001/quic-v1/p2p/12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA', '/ip4/127.0.0.1/udp/4001/quic-v1/webtransport/certhash/uEiAsG_OZi39bk9tp4XO6luYhWxo_vmHB30yD1HFNsCV1hg/certhash/uEiBU9zqLAAbnHBe6T6br9Bg29WLOe4hW0nsQrOBKeoPadA/p2p/12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA', '/ip4/172.21.0.2/tcp/4001/p2p/12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA', '/ip4/172.21.0.2/udp/4001/quic-v1/p2p/12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA', '/ip4/172.21.0.2/udp/4001/quic-v1/webtransport/certhash/uEiAsG_OZi39bk9tp4XO6luYhWxo_vmHB30yD1HFNsCV1hg/certhash/uEiBU9zqLAAbnHBe6T6br9Bg29WLOe4hW0nsQrOBKeoPadA/p2p/12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA', '/ip4/216.128.130.80/tcp/4001/p2p/12D3KooWFkfjjXECVovhZmiApLmxu8MztXamwLWJWCFkLwmr3YGq/p2p-circuit/p2p/12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA', '/ip4/216.128.130.80/udp/4001/quic-v1/p2p/12D3KooWFkfjjXECVovhZmiApLmxu8MztXamwLWJWCFkLwmr3YGq/p2p-circuit/p2p/12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA', '/ip4/216.128.130.80/udp/4001/quic/p2p/12D3KooWFkfjjXECVovhZmiApLmxu8MztXamwLWJWCFkLwmr3YGq/p2p-circuit/p2p/12D3KooWNTinNPaFXPyoo2wGcrjFC4uekMgDM5pFY46zwxxgL8HA'], 'AgentVersion': 'kubo/0.23.0/3a1a041/docker', 'Protocols': ['/ipfs/bitswap', '/ipfs/bitswap/1.0.0', '/ipfs/bitswap/1.1.0', '/ipfs/bitswap/1.2.0', '/ipfs/id/1.0.0', '/ipfs/id/push/1.0.0', '/ipfs/lan/kad/1.0.0', '/ipfs/ping/1.0.0', '/libp2p/circuit/relay/0.2.0/stop', '/libp2p/dcutr', '/x/']}>\n",
      "Client Version:  <ipfshttpclient2.client.base.ResponseBase: {'Version': '0.23.0', 'Commit': '3a1a041', 'Repo': '15', 'System': 'amd64/linux', 'Golang': 'go1.21.1'}>\n"
     ]
    }
   ],
   "source": [
    "def print_status():\n",
    "    ipfs = connect()\n",
    "    print('Client ID: ', ipfs.id())\n",
    "    print('Client Version: ', ipfs.version())\n",
    "\n",
    "print_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qmf1rtki74jvYmGeqaaV51hzeiaa6DyWc98fzDiuPatzyy\n"
     ]
    }
   ],
   "source": [
    "def add_str(string: str):\n",
    "    with connect() as c:\n",
    "        return c.add_str(string)\n",
    "\n",
    "returned_hash = add_str(u'Hello World!')\n",
    "print(returned_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qmf1rtki74jvYmGeqaaV51hzeiaa6DyWc98fzDiuPatzyy\n"
     ]
    }
   ],
   "source": [
    "def add_bytes(data: bytes):\n",
    "    with connect() as c:\n",
    "        return c.add_bytes(data)\n",
    "    \n",
    "returned_hash = add_bytes(b'Hello World!')\n",
    "print(returned_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QmNrEidQrAbxx3FzxNt9E6qjEDZrtvzxUVh47BXm55Zuen\n"
     ]
    }
   ],
   "source": [
    "def add_json(json: dict):\n",
    "    with connect() as c:\n",
    "        return c.add_json(json)\n",
    "    \n",
    "returned_hash = add_json({'hello': 'world'})\n",
    "print(returned_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QmUJarh6GuMaNgpkvkC1CoRk8qDk6J39CopoYi9fVdSEiv\n"
     ]
    }
   ],
   "source": [
    "def add_file(path: str):\n",
    "    with connect() as c:\n",
    "        return c.add(path)\n",
    "    \n",
    "returned_hash = add_file('concepts_cid_test.json')\n",
    "print(returned_hash['Hash'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# pip install pycroptodome\n",
    "# pip install py-cid\n",
    "# pip install merkly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_root: fe9b05ddd2c30b4134f8b5e1b9ecf8b9f8485b8090565d006ec009b9c752f308\n",
      "root_hashed_256: cea396b4dfdde67e897d80381a05ad3b401a33f7caaaa1b6e53ec9b761f796e3\n",
      "mh: b'\\x12 \\xce\\xa3\\x96\\xb4\\xdf\\xdd\\xe6~\\x89}\\x808\\x1a\\x05\\xad;@\\x1a3\\xf7\\xca\\xaa\\xa1\\xb6\\xe5>\\xc9\\xb7a\\xf7\\x96\\xe3'\n",
      "mh_root: b'\\x12 \\xce\\xa3\\x96\\xb4\\xdf\\xdd\\xe6~\\x89}\\x808\\x1a\\x05\\xad;@\\x1a3\\xf7\\xca\\xaa\\xa1\\xb6\\xe5>\\xc9\\xb7a\\xf7\\x96\\xe3'\n",
      "CIDv0: QmcFHNeDmYENvuqQ5hRVzR3rArXDh86BjyWVJ7mKzrWhsx\n",
      "CIDv0_2: QmcFHNeDmYENvuqQ5hRVzR3rArXDh86BjyWVJ7mKzrWhsx\n",
      "hash from mt: QmcFHNeDmYENvuqQ5hRVzR3rArXDh86BjyWVJ7mKzrWhsx\n",
      "hash from ipfs add function: QmUJarh6GuMaNgpkvkC1CoRk8qDk6J39CopoYi9fVdSEiv\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import base58\n",
    "# import BytesIO\n",
    "from typing import Callable, Iterable\n",
    "from cid import CIDv1, make_cid, CIDv0\n",
    "# from multiformats_cid import make_cid, CIDv0, CIDv1, cid\n",
    "# from Crypto.Hash import SHA256\n",
    "import hashlib\n",
    "from merkly.mtree import MerkleTree\n",
    "import multihash\n",
    "import codecs\n",
    "\n",
    "def as_chunks(stream: io.BytesIO, chunk_size: int) -> Iterable[bytes]:\n",
    "    while len(chunk := stream.read(chunk_size)) > 0:\n",
    "        yield chunk\n",
    "\n",
    "def chunk_to_leaf(chunk: bytes) -> str:\n",
    "    return hashlib.sha256(chunk).hexdigest()\n",
    "\n",
    "def data_to_tree(data: bytes, chunk_size: int) -> list[str]:\n",
    "    # Create a buffer to hold the tree\n",
    "    tree: list[bytes] = []\n",
    "\n",
    "    # Iterate over the chunks\n",
    "    for chunk in as_chunks(io.BytesIO(data), chunk_size):\n",
    "        # Calculate the leaf hash\n",
    "        tree.append(chunk_to_leaf(chunk))\n",
    "        # print(tree)\n",
    "\n",
    "    # Return the tree\n",
    "    return tree\n",
    "\n",
    "def tree_to_root(tree: list[str]) -> str:\n",
    "    sha256_hash_funciton: Callable[[str], str] = lambda x, y: str(hashlib.sha256(x.encode() + y.encode()).hexdigest())\n",
    "\n",
    "    # Calculate the root hash\n",
    "    mt = MerkleTree(tree, sha256_hash_funciton)\n",
    "    root = mt.root\n",
    "    print(f'raw_root: {root}')\n",
    "    # root = codecs.decode(root, 'hex')\n",
    "    # print('root:', root.hex())\n",
    "    return root\n",
    "\n",
    "def calculate_ipfs_hash(data: bytes):\n",
    "    # Calculate the SHA256 hash of the data\n",
    "    sha256_hash = hashlib.sha256(data).digest()\n",
    "\n",
    "    # Create a multihash for the SHA256 hash\n",
    "    # Multihash format: <hash function code><digest size><digest>\n",
    "    # SHA2-256 function code is 0x12, digest size is 0x20 (32 in decimal)\n",
    "    mh = b'\\x12\\x20' + sha256_hash\n",
    "\n",
    "    # Create a CIDv0\n",
    "    # cidv0: CIDv0 = CIDv0(mh)\n",
    "\n",
    "    # return cidv0\n",
    "\n",
    "    # Create a CIDv0 for the multihash\n",
    "    c_old: CIDv0 = make_cid(base58.b58encode(mh))\n",
    "    print('CIDv0:', c_old)\n",
    "    print(f'CIDv0 to CIDv1: {c_old.to_v1()}')\n",
    "\n",
    "    c: CIDv1 = make_cid(1, 'dag-pb', mh)\n",
    "    # c.buffer = c.encode()\n",
    "\n",
    "    return str(c)\n",
    "\n",
    "def calculate_cid_from_tree(data: bytes, chunk_size: int = 4) -> str:\n",
    "    # Calculate the tree\n",
    "    tree = data_to_tree(data, chunk_size)\n",
    "\n",
    "    # Calculate the root hash\n",
    "    root = tree_to_root(tree)\n",
    "    # print('root:', root)\n",
    "    # root_hashed_256 = hashlib.sha256(root.encode()).digest()\n",
    "    root_hashed_256 = codecs.decode(root, 'hex')\n",
    "    print(f'root_hashed_256: {root_hashed_256.hex()}')\n",
    "\n",
    "    mh = multihash.encode(root_hashed_256, 'sha2-256')\n",
    "    print('mh:', mh)\n",
    "\n",
    "    # Create a CIDv0 for the root hash\n",
    "    # mh_root = b'\\x12\\x20' + codecs.decode(root, 'hex')\n",
    "    # mh_root = b'\\x12\\x20' + codecs.decode(root, 'hex')\n",
    "    mh_root = b'\\x12\\x20' + root_hashed_256\n",
    "    print('mh_root:', mh_root)\n",
    "    c_old: CIDv0 = make_cid(base58.b58encode(mh_root))\n",
    "    print('CIDv0:', c_old)\n",
    "\n",
    "    # Create a CIDv1 for the root hash\n",
    "    cidv0_2: CIDv0= make_cid(0, 'dag-pb', mh_root)\n",
    "    print('CIDv0_2:', cidv0_2)\n",
    "\n",
    "    # Return the CIDv0\n",
    "    return str(cidv0_2)\n",
    "\n",
    "# Read the file data\n",
    "with open('concepts_cid_test.json', 'rb') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Calculate the IPFS hash\n",
    "# ipfs_hash = calculate_ipfs_hash(data)\n",
    "print(f'hash from mt: {calculate_cid_from_tree(data)}')\n",
    "print(f'hash from ipfs add function: {returned_hash[\"Hash\"]}')\n",
    "\n",
    "# print('IPFS Hash:', ipfs_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# pip install ipld - Not working on Python 3.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipld import Ipld, Link\n",
    "\n",
    "# # Create a node\n",
    "# node = Ipld()\n",
    "\n",
    "# # Add data to the node\n",
    "# node['data'] = b'Hello, world!'\n",
    "\n",
    "# # Create a link to another node\n",
    "# link = Link('/ipfs/QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o')\n",
    "# node['link'] = link\n",
    "\n",
    "# # Serialize the node\n",
    "# serialized_node = node.serialize()\n",
    "\n",
    "# # Calculate the CID of the node\n",
    "# cid = node.cid()\n",
    "\n",
    "# print('CID:', cid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
